{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/kssocha/Desktop/Nauka/portfolio/2024-gold-price-prediction-with-lstm-model/data/raw/2024-04-06_09:28_yf_au_data_.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the percentage change\n",
    "df['returns'] = df['Close_gold'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the log returns\n",
    "#https://quantivity.wordpress.com/2011/02/21/why-log-returns/\n",
    "df['log_returns'] = np.log(1 + df['returns'])\n",
    "\n",
    "#drop rows with missing values\n",
    "df = df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature matrix X\n",
    "X = df[['Close_gold', 'log_returns']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data normalization with MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "#create target vector y\n",
    "y = [x[0] for x in X_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split into train, test and validation sets\n",
    "split_1 = int(len(X_scaled) * 0.8)\n",
    "split_2 = int(len(X_scaled) * 0.95)\n",
    "\n",
    "X_train = X_scaled[:split_1]\n",
    "X_validation = X_scaled[split_1 : split_2]\n",
    "X_test = X_scaled[split_2 : len(X_scaled)]\n",
    "y_train = y[:split_1]\n",
    "y_validation = y[split_1 : split_2]\n",
    "y_test = y[split_2 : len(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the lengths\n",
    "assert len(X_train) == len(y_train)\n",
    "assert len(X_validation) == len(y_validation)\n",
    "assert len(X_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labeling\n",
    "n = 3\n",
    "Xtrain = []\n",
    "ytrain = []\n",
    "Xvalidation = []\n",
    "yvalidation = []\n",
    "Xtest = []\n",
    "ytest = []\n",
    "for i in range(n, len(X_train)):\n",
    "    Xtrain.append(X_train[i - n: i, : X_train.shape[1]])\n",
    "    ytrain.append(y_train[i])\n",
    "for i in range(n, len(X_test)):\n",
    "    Xtest.append(X_test[i - n: i, : X_test.shape[1]])\n",
    "    ytest.append(y_test[i])\n",
    "for i in range(n,len(X_validation)):\n",
    "    Xvalidation.append(X_validation[i - n: i, : X_validation.shape[1]])\n",
    "    yvalidation.append(y_validation[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM inputs reshaping\n",
    "Xtrain, ytrain = (np.array(Xtrain), np.array(ytrain))\n",
    "Xtrain = np.reshape(Xtrain, (Xtrain.shape[0], Xtrain.shape[1], Xtrain.shape[2]))\n",
    "\n",
    "Xvalidation, yvalidation = (np.array(Xvalidation), np.array(yvalidation))\n",
    "Xvalidation = np.reshape(Xvalidation, (Xvalidation.shape[0], Xvalidation.shape[1], Xvalidation.shape[2]))\n",
    "\n",
    "Xtest, ytest = (np.array(Xtest), np.array(ytest))\n",
    "Xtest = np.reshape(Xtest, (Xtest.shape[0], Xtest.shape[1], Xtest.shape[2]))\n",
    "\n",
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xvalidation.shape)\n",
    "print(yvalidation.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "model = load_model('/home/kssocha/Desktop/Nauka/portfolio/2024-gold-price-prediction-with-lstm-model/models/2024-04-17/2024-04-17-models/2024-04-17_lstm_model_27.h5')\n",
    "\n",
    "#prediction\n",
    "train_predict = model.predict(Xtrain)\n",
    "validation_predict = model.predict(Xvalidation)\n",
    "test_predict = model.predict(Xtest)\n",
    "\n",
    "train_predict = np.c_[train_predict, np.zeros(train_predict.shape)]\n",
    "validation_predict = np.c_[validation_predict, np.zeros(validation_predict.shape)]\n",
    "test_predict = np.c_[test_predict, np.zeros(test_predict.shape)]\n",
    "\n",
    "#invert prediction\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "train_predict = [x[0] for x in train_predict]\n",
    "\n",
    "validation_predict = scaler.inverse_transform(validation_predict)\n",
    "validation_predict = [x[0] for x in validation_predict]\n",
    "\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "test_predict = [x[0] for x in test_predict]\n",
    "\n",
    "#calculate square root of mean squared error\n",
    "train_score = root_mean_squared_error([x[0][0] for x in Xtrain], train_predict)\n",
    "print('Train Score: %.2f RMSE' % (train_score))\n",
    "\n",
    "validation_score = root_mean_squared_error([x[0][0] for x in Xvalidation], validation_predict)\n",
    "print('Validation Score: %.2f RMSE' % (validation_score))\n",
    "\n",
    "test_score = root_mean_squared_error([x[0][0] for x in Xtest], test_predict)\n",
    "print('Test Score: %.2f RMSE' % (test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split into train and test\n",
    "df_train = df[n:split_1]\n",
    "df_validation = df[split_1+n : split_2]\n",
    "df_test = df[split_2+n : len(X_scaled)]\n",
    "\n",
    "df_test['predictions'] = test_predict\n",
    "\n",
    "#plot actual vs predicted values\n",
    "\n",
    "df_train.set_index('Date', inplace=True)\n",
    "df_validation.set_index('Date', inplace=True)\n",
    "df_test.set_index('Date', inplace=True)\n",
    "\n",
    "plt.plot(df_train.iloc[-(int(0.25*len(df_train))):]['Close_gold'], label='25% of Train')\n",
    "plt.plot(df_validation['Close_gold'], label='Validation')\n",
    "plt.plot(df_test['Close_gold'], label='Actual')\n",
    "plt.plot(df_test['predictions'], label='Forecast')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=90)\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(20))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate confidence interval using bootstrapping\n",
    "\n",
    "from scipy.stats import bootstrap\n",
    "\n",
    "interval = 10 #approximately 2 weeks data\n",
    "low_ci = []\n",
    "high_ci = []\n",
    "\n",
    "for n in range(0, len(df_test) - interval):\n",
    "    #convert data to sequence\n",
    "    data = df_test['predictions'][n : n+interval].values.tolist()\n",
    "    data = (data,)\n",
    "\n",
    "    bootstrap_ci = bootstrap(data, np.median, confidence_level = .95, random_state = 1, method = 'percentile')\n",
    "    \n",
    "    low_ci.append(bootstrap_ci.confidence_interval.low)\n",
    "    high_ci.append(bootstrap_ci.confidence_interval.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(df_train.iloc[-(int(0.25*len(df_train))):]['Close_gold'], label='25% of Train')\n",
    "#plt.plot(df_validation['Close_gold'], label='Validation')\n",
    "plt.plot(df_test['Close_gold'], label='Actual')\n",
    "plt.plot(df_test['predictions'], label='Forecast')\n",
    "plt.fill_between(df_test[0:-interval].index, low_ci, high_ci, color='gray', alpha=0.3)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=90)\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(20))\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
